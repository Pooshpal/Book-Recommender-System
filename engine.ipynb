{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./Dataset/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD & CHECK DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from PIL import Image\n",
    "import requests\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books=pd.read_csv(\"Dataset\\Books.csv\")\n",
    "books.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=pd.read_csv(\"Dataset/Ratings.csv\")\n",
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=pd.read_csv(\"Dataset/Users.csv\")\n",
    "users.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Books Shape: \" ,books.shape )\n",
    "print(\"Ratings Shape: \" ,ratings.shape )\n",
    "print(\"Users Shape: \" ,users.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Any null values in Books:\\n\" ,books.isnull().sum())\n",
    "print(\"Any null values in Ratings:\\n \",ratings.isnull().sum())\n",
    "print(\"Any null values in Users:\\n\",users.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data=books.merge(ratings,on=\"ISBN\")\n",
    "books_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=books_data.copy()\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.drop(columns=[\"ISBN\",\"Year-Of-Publication\",\"Image-URL-S\",\"Image-URL-M\"],axis=1,inplace=True)\n",
    "df.drop(index=df[df[\"Book-Rating\"]==0].index,inplace=True)\n",
    "df[\"Book-Title\"]=df[\"Book-Title\"].apply(lambda x: re.sub(\"[\\W_]+\",\" \",x).strip())\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **POPULARITY BASED RECOMMENDATION SYSTEM**\n",
    "\n",
    "* Popularity based recommendation systems are based on the rating of items by all the users.\n",
    "* Popularity based recommendation systems works with the trend. It basically uses the items which are in trend right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_books(df,n=100):\n",
    "    rating_count=df.groupby(\"Book-Title\").count()[\"Book-Rating\"].reset_index()\n",
    "    rating_count.rename(columns={\"Book-Rating\":\"NumberOfVotes\"},inplace=True)\n",
    "    \n",
    "    rating_average=df.groupby(\"Book-Title\")[\"Book-Rating\"].mean().reset_index()\n",
    "    rating_average.rename(columns={\"Book-Rating\":\"AverageRatings\"},inplace=True)\n",
    "    \n",
    "    popularBooks=rating_count.merge(rating_average,on=\"Book-Title\")\n",
    "    \n",
    "    def weighted_rate(x):\n",
    "        v=x[\"NumberOfVotes\"]\n",
    "        R=x[\"AverageRatings\"]\n",
    "        \n",
    "        return ((v*R) + (m*C)) / (v+m)\n",
    "    \n",
    "    C=popularBooks[\"AverageRatings\"].mean()\n",
    "    m=popularBooks[\"NumberOfVotes\"].quantile(0.90)\n",
    "    \n",
    "    popularBooks=popularBooks[popularBooks[\"NumberOfVotes\"] >=250]\n",
    "    popularBooks[\"Popularity\"]=popularBooks.apply(weighted_rate,axis=1)\n",
    "    popularBooks=popularBooks.sort_values(by=\"Popularity\",ascending=False)\n",
    "    return popularBooks[[\"Book-Title\",\"NumberOfVotes\",\"AverageRatings\",\"Popularity\"]].reset_index(drop=True).head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "top_ten=pd.DataFrame(popular_books(df,10))\n",
    "display(top_ten)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **USER-BASED COLLABORATIVE FILTERING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=df[df['User-ID'].map(df['User-ID'].value_counts()) > 200]  # Drop users who vote less than 200 times.\n",
    "users_pivot=new_df.pivot_table(index=[\"User-ID\"],columns=[\"Book-Title\"],values=\"Book-Rating\")\n",
    "users_pivot.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_choice(id):\n",
    "    \n",
    "    users_fav=new_df[new_df[\"User-ID\"]==id].sort_values([\"Book-Rating\"],ascending=False)[0:5]\n",
    "    return users_fav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based(new_df,id):\n",
    "    if id not in new_df[\"User-ID\"].values:\n",
    "        print(\"‚ùå User NOT FOUND ‚ùå\")\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        index=np.where(users_pivot.index==id)[0][0]\n",
    "        similarity=cosine_similarity(users_pivot)\n",
    "        similar_users=list(enumerate(similarity[index]))\n",
    "        similar_users = sorted(similar_users,key = lambda x:x[1],reverse=True)[0:5]\n",
    "    \n",
    "        user_rec=[]\n",
    "    \n",
    "        for i in similar_users:\n",
    "                data=df[df[\"User-ID\"]==users_pivot.index[i[0]]]\n",
    "                user_rec.extend(list(data.drop_duplicates(\"User-ID\")[\"User-ID\"].values))\n",
    "        \n",
    "    return user_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common(new_df,user,user_id):\n",
    "    x=new_df[new_df[\"User-ID\"]==user_id]\n",
    "    recommend_books=[]\n",
    "    user=list(user)\n",
    "    for i in user:\n",
    "        y=new_df[(new_df[\"User-ID\"]==i)]\n",
    "        books=y.loc[~y[\"Book-Title\"].isin(x[\"Book-Title\"]),:]\n",
    "        books=books.sort_values([\"Book-Rating\"],ascending=False)[0:5]\n",
    "        recommend_books.extend(books[\"Book-Title\"].values)\n",
    "        \n",
    "    return recommend_books[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id=random.choice(new_df[\"User-ID\"].values)\n",
    "user_choice_df=pd.DataFrame(users_choice(user_id))\n",
    "user_favorite=users_choice(user_id)\n",
    "n=len(user_choice_df[\"Book-Title\"].values)\n",
    "print(\"üü¶ USER: {} \".format(user_id))\n",
    "#print(user_choice_df)\n",
    "\n",
    "user_based_rec=user_based(new_df,user_id)\n",
    "books_for_user=common(new_df,user_based_rec,user_id)\n",
    "books_for_userDF=pd.DataFrame(books_for_user,columns=[\"Book-Title\"])\n",
    "display(books_for_userDF.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CONTENT-BASED COLLABORATIVE FILTERING** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based(bookTitle):\n",
    "    bookTitle=str(bookTitle)\n",
    "    \n",
    "    if bookTitle in df[\"Book-Title\"].values:\n",
    "        rating_count=pd.DataFrame(df[\"Book-Title\"].value_counts())\n",
    "        rare_books=rating_count[rating_count[\"Book-Title\"]<=200].index\n",
    "        common_books=df[~df[\"Book-Title\"].isin(rare_books)]\n",
    "        \n",
    "        if bookTitle in rare_books:\n",
    "            most_common=pd.Series(common_books[\"Book-Title\"].unique()).sample(3).values\n",
    "            print(\"No Recommendations for this Book ‚òπÔ∏è \\n \")\n",
    "            print(\"YOU MAY TRY: \\n \")\n",
    "            print(\"{}\".format(most_common[0]), \"\\n\")\n",
    "            print(\"{}\".format(most_common[1]), \"\\n\")\n",
    "            print(\"{}\".format(most_common[2]), \"\\n\")\n",
    "        else:\n",
    "            common_books=common_books.drop_duplicates(subset=[\"Book-Title\"])\n",
    "            common_books.reset_index(inplace=True)\n",
    "            common_books[\"index\"]=[i for i in range(common_books.shape[0])]\n",
    "            targets=[\"Book-Title\",\"Book-Author\",\"Publisher\"]\n",
    "            common_books[\"all_features\"] = [\" \".join(common_books[targets].iloc[i,].values) for i in range(common_books[targets].shape[0])]\n",
    "            vectorizer=CountVectorizer()\n",
    "            common_booksVector=vectorizer.fit_transform(common_books[\"all_features\"])\n",
    "            similarity=cosine_similarity(common_booksVector)\n",
    "            index=common_books[common_books[\"Book-Title\"]==bookTitle][\"index\"].values[0]\n",
    "            similar_books=list(enumerate(similarity[index]))\n",
    "            similar_booksSorted=sorted(similar_books,key=lambda x:x[1],reverse=True)[1:6]\n",
    "            books=[]\n",
    "            for i in range(len(similar_booksSorted)):\n",
    "                \n",
    "                books.append(common_books[common_books[\"index\"]==similar_booksSorted[i][0]][\"Book-Title\"].item())\n",
    "            #fig,ax=plt.subplots(1,5,figsize=(17,5))\n",
    "            #fig.suptitle(\"YOU MAY ALSO LIKE THESE BOOKS\",fontsize=40,color=\"chocolate\")\n",
    "            display(books)\n",
    "    else:\n",
    "        print(\"‚ùå COULD NOT FIND ‚ùå\")               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based(\"The Da Vinci Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based(\"A Soldier of the Great War\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EVALUATION METRIC** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Tail Plot Example\n",
    "import recmetrics\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "recmetrics.long_tail_plot(df=ratings, \n",
    "             item_id_column=\"User-ID\", \n",
    "             interaction_type=\"Book-Rating\", \n",
    "             percentage=0.5,\n",
    "             x_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "#Format data for Surprise\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(ratings[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "#Train SVD Recommender\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "#Make predictions on SVD test set\n",
    "test = algo.test(testset)\n",
    "test = pd.DataFrame(test)\n",
    "test.drop(\"details\", inplace=True, axis=1)\n",
    "test.columns = ['userId', 'movieId', 'actual', 'cf_predictions']\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
